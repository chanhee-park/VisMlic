{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNNfor MNIST Dataset\n",
    "\n",
    "### 패키지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.utils import to_categorical\n",
    "from keras import losses\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from skimage import io\n",
    "\n",
    "import theano\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Functions \n",
    "def get_hot_idx(arr):\n",
    "    return arr.index(max(arr))\n",
    "\n",
    "def save_to_json_file(data, filename):\n",
    "    with open(filename, 'w') as outfile:\n",
    "        json.dump(data, outfile)\n",
    "    print(filename + ' 저장완료')\n",
    "    \n",
    "def get_round_array(array, decimal):\n",
    "    return [round(e, decimal) for e in array]\n",
    "\n",
    "def get_activations(model, layer, X_batch):\n",
    "    get_activations = K.function([model.layers[0].input, K.learning_phase()], [model.layers[layer].output,])\n",
    "    activations = get_activations([X_batch,0])\n",
    "    return activations\n",
    "\n",
    "def get_arr_from_json_file(filename):\n",
    "    input_file = open (filename)\n",
    "    return json.load(input_file)\n",
    "    \n",
    "current_milli_time = lambda: int(round(time.time() * 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터셋 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 관련 파라메터 정의\n",
    "img_rows, img_cols = 28, 28\n",
    "num_of_feature = img_rows * img_cols \n",
    "\n",
    "num_of_class = 10\n",
    "num_of_trainset = 10000\n",
    "num_of_testset = 10000\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)[:num_of_trainset]\n",
    "Y_tarin = Y_train[:num_of_trainset]\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)[:num_of_testset]\n",
    "Y_test = Y_test[:num_of_testset]\n",
    "\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = keras.utils.to_categorical(Y_train, num_of_class)\n",
    "Y_test = keras.utils.to_categorical(Y_test, num_of_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로컬 테스트 데이터 로드\n",
    "images = np.zeros((10000, 784))\n",
    "for real in range(10):\n",
    "    for idx in range(1, 1001):\n",
    "        file = '../../data/mnist/images/'+ str(real) + '/' + str(real) + '_' + str(idx) +'.png'\n",
    "        image = np.ndarray.flatten(io.imread(file)) / 255.0\n",
    "        image = np.array([1 - pixel for pixel in image])\n",
    "        images[real * 1000 + idx - 1] = image\n",
    "\n",
    "images = images.reshape(images.shape[0], img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(num_of_class, activation='softmax'))\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "10000/10000 [==============================] - 3s 277us/step - loss: 0.4720 - acc: 0.8618 - val_loss: 0.2696 - val_acc: 0.9199\n",
      "Epoch 2/3\n",
      "10000/10000 [==============================] - 3s 250us/step - loss: 0.2136 - acc: 0.9399 - val_loss: 0.1930 - val_acc: 0.9447\n",
      "Epoch 3/3\n",
      "10000/10000 [==============================] - 3s 257us/step - loss: 0.1569 - acc: 0.9558 - val_loss: 0.1534 - val_acc: 0.9565\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb033980ac8>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train[:num_of_trainset],\n",
    "          epochs=3,\n",
    "          batch_size=32,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 테스트 셋 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 56us/step\n",
      "loss_and_metrics : [0.1534139785528183, 0.9565]\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics = model.evaluate(X_test, Y_test, batch_size=32)\n",
    "print('loss_and_metrics : ' + str(loss_and_metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 내 데이터로 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측\n",
    "pred_proba =  model.predict_proba(images).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.9494, 'recall': [0.968, 0.961, 0.956, 0.963, 0.977, 0.914, 0.973, 0.945, 0.914, 0.923], 'precision': [0.968, 0.9806, 0.9087, 0.9198, 0.9403, 0.9775, 0.9586, 0.9394, 0.9551, 0.9525]}\n"
     ]
    }
   ],
   "source": [
    "# 성능 확인 및 저장\n",
    "correct = 0\n",
    "performances = {\n",
    "    \"accuracy\": 0,\n",
    "    \"recall\": [0] * 10,\n",
    "    \"precision\": [0] * 10\n",
    "}\n",
    "truePredict = [0] * 10\n",
    "numOfPredict = [0] * 10\n",
    "predicts = []\n",
    "\n",
    "for i in range(len(pred_proba)):\n",
    "    prob = pred_proba[i]\n",
    "    pred = get_hot_idx(prob)\n",
    "    real = i // 1000\n",
    "    predicts.append(dict({\n",
    "        \"real\": real,\n",
    "        \"pred\": pred,\n",
    "        \"prob\": [round(e, 4) for e in prob]\n",
    "    }))\n",
    "    numOfPredict[pred] = numOfPredict[pred] + 1\n",
    "    if pred is real:\n",
    "        truePredict[real] = truePredict[real] + 1\n",
    "        correct = correct + 1\n",
    "\n",
    "performances[\"accuracy\"] = correct / 10000\n",
    "performances[\"recall\"] = [round(truePredict[i] / 1000, 4) for i in range(10) ]\n",
    "performances[\"precision\"] = [round(truePredict[i] / numOfPredict[i], 4) for i in range(10)]\n",
    "\n",
    "print(performances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 차원축소\n",
    "\n",
    "1) 마지막 직전의 레이어에서 activation values를 뽑는다.\n",
    "\n",
    "2) t-SNE로 차원을 축소한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "samples = []\n",
    "idxs = get_arr_from_json_file('./sample_image_idxs.json')\n",
    "for idx in idxs:\n",
    "    samples.append(images[idx])\n",
    "print(len(samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_features = get_activations(model, -2, samples)[0]\n",
    "y = TSNE(n_components=2).fit_transform(extracted_features)\n",
    "sne_map = []\n",
    "for e in y:\n",
    "    sne_map.append({\n",
    "        \"x\": round(e[0], 2),\n",
    "        \"y\": round(e[1], 2)\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = {\n",
    "    \"model_name\": 'Convolutional Neural Network',\n",
    "    \"short_name\": 'CNN',\n",
    "    \"description\": '1개의 Convolution2D 레이어와 1개의 Dense 레이어를 가지는 모델이다.',\n",
    "    \"performance\": {\n",
    "        \"accuracy\": performances[\"accuracy\"],\n",
    "        \"recall\": performances[\"recall\"],\n",
    "        \"precision\": performances[\"precision\"]\n",
    "    },\n",
    "    \"predict\": predicts,\n",
    "    \"t-sne\": sne_map\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mnist_cnn.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(str(model_data), f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
