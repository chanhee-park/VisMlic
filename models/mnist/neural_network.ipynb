{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Model for MNIST Dataset\n",
    "\n",
    "### 패키지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from skimage import io\n",
    "\n",
    "import theano\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions \n",
    "def get_hot_idx(arr):\n",
    "    return arr.index(max(arr))\n",
    "\n",
    "def save_to_json_file(data, filename):\n",
    "    with open(filename, 'w') as outfile:\n",
    "        json.dump(data, outfile)\n",
    "    print(filename + ' 저장완료')\n",
    "    \n",
    "def get_round_array(array, decimal):\n",
    "    return [round(e, decimal) for e in array]\n",
    "\n",
    "def get_activations(model, layer, X_batch):\n",
    "    get_activations = K.function([model.layers[0].input, K.learning_phase()], [model.layers[layer].output,])\n",
    "    activations = get_activations([X_batch,0])\n",
    "    return activations\n",
    "\n",
    "def get_arr_from_json_file(filename):\n",
    "    input_file = open (filename)\n",
    "    return json.load(input_file)\n",
    "    \n",
    "current_milli_time = lambda: int(round(time.time() * 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터셋 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_width = 28\n",
    "image_height = 28\n",
    "num_of_features = image_width * image_height\n",
    "\n",
    "num_of_class = 10\n",
    "num_of_trainset = 60000\n",
    "num_of_testset = 10000\n",
    "\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "X_train = X_train.reshape(num_of_trainset, num_of_features).astype('float32') / 255.0\n",
    "X_test = X_test.reshape(num_of_testset, num_of_features).astype('float32') / 255.0\n",
    "Y_train = np_utils.to_categorical(Y_train)\n",
    "Y_test = np_utils.to_categorical(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로컬 테스트 데이터 로드\n",
    "images = np.zeros((10000, 784))\n",
    "for real in range(10):\n",
    "    for idx in range(1, 1001):\n",
    "        file = '../../data/mnist/images/'+ str(real) + '/' + str(real) + '_' + str(idx) +'.png'\n",
    "        image = np.ndarray.flatten(io.imread(file)) / 255.0\n",
    "        image = np.array([1 - pixel for pixel in image])\n",
    "        images[real * 1000 + idx - 1] = image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 구축 \n",
    "model = Sequential()\n",
    "model.add(Dense(units=128, input_dim=num_of_features, activation='relu'))\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "model.add(Dense(units=32, activation='relu'))\n",
    "model.add(Dense(units=16, activation='relu'))\n",
    "model.add(Dense(units=10, activation='relu'))\n",
    "model.add(Dense(units=num_of_class, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 1472/60000 [..............................] - ETA: 1:12 - loss: 2.2968 - acc: 0.1447  ETA: 23:20 - loss: 2.3181 - acc: 0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.137419). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 10s 166us/step - loss: 1.2879 - acc: 0.5706\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 9s 142us/step - loss: 0.4151 - acc: 0.8832\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.2645 - acc: 0.92530s - loss: 0.2679 - acc: 0.924 - ETA: 0s - loss: 0.2677 -\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - ETA: 0s - loss: 0.2058 - acc: 0.9414- ETA: 5s - loss: 0.21 - E - ETA: 2s - loss: - 10s 173us/step - loss: 0.2054 - acc: 0.9416\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 9s 147us/step - loss: 0.1682 - acc: 0.9523\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 11s 180us/step - loss: 0.1446 - acc: 0.9580\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 11s 177us/step - loss: 0.1273 - acc: 0.96378s -  - ETA: 0s - loss: 0.1278 - a\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 10s 167us/step - loss: 0.1108 - acc: 0.9676\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 10s 174us/step - loss: 0.0992 - acc: 0.97127 - ETA: 5s - loss: - ETA: 3s - loss: 0.0975 - acc: 0. - ETA:\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 10s 158us/step - loss: 0.0873 - acc: 0.97431s - \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x10abf2e90>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 테스트 셋 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 48us/step\n",
      "loss_and_metrics : [0.14955389682762324, 0.9558]\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics = model.evaluate(X_test, Y_test, batch_size=32)\n",
    "print('loss_and_metrics : ' + str(loss_and_metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 내 데이터로 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측\n",
    "pred_proba =  model.predict_proba(images).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9513\n"
     ]
    }
   ],
   "source": [
    "# 성능확인 \n",
    "correct = 0\n",
    "res = []\n",
    "for i in range(len(pred_proba)):\n",
    "    prob = pred_proba[i]\n",
    "    pred = get_hot_idx(prob)\n",
    "    real = i // 1000\n",
    "    res.append([real, pred, real is pred, i])\n",
    "    if pred is real:\n",
    "        correct = correct + 1\n",
    "print(correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 차원축소\n",
    "\n",
    "1) 마지막 직전의 레이어에서 activation values를 뽑는다.\n",
    "\n",
    "2) t-SNE로 차원을 축소한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "samples = []\n",
    "idxs = get_arr_from_json_file('./sample_image_idxs.json')\n",
    "for idx in idxs:\n",
    "    samples.append(images[idx])\n",
    "print(len(samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_features = get_activations(model, -2, samples)[0]\n",
    "y = TSNE(n_components=2).fit_transform(extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
